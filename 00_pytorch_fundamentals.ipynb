{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pyarrow-15.0.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in c:\\users\\gijin100\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyarrow) (1.26.4)\n",
      "Downloading pyarrow-15.0.0-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/25.3 MB 825.8 kB/s eta 0:00:31\n",
      "    --------------------------------------- 0.4/25.3 MB 3.5 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.9/25.3 MB 5.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.4/25.3 MB 6.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.9/25.3 MB 7.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.3/25.3 MB 8.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.7/25.3 MB 8.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.3/25.3 MB 8.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 9.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/25.3 MB 9.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.8/25.3 MB 9.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.2/25.3 MB 9.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.8/25.3 MB 9.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.3/25.3 MB 9.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/25.3 MB 10.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.9/25.3 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.3/25.3 MB 10.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.8/25.3 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.4/25.3 MB 10.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.9/25.3 MB 10.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.4/25.3 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.5/25.3 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.9/25.3 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.5/25.3 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.0/25.3 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.5/25.3 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.0/25.3 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.5/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.0/25.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.6/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.1/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.6/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.1/25.3 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.6/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.1/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.7/25.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.2/25.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.7/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.2/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.7/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.2/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.7/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.2/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.7/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.3/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.7/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.2/25.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.7/25.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.3/25.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 10.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-15.0.0\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 2, 3],\n",
       "         [1, 2, 4]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Tensor = torch.tensor([[[1,2,3],[1,2,3],[1,2,4],]])\n",
    "Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(Tensor.shape)\n",
    "print(Tensor[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6637, 0.5922, 0.5477, 0.8690],\n",
      "        [0.1205, 0.9501, 0.1540, 0.3778],\n",
      "        [0.9061, 0.9813, 0.0986, 0.4943]]) tensor([3, 4, 5])\n",
      "3\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#random \n",
    "rand_torch = torch.rand(3,4)\n",
    "range_torch = torch.arange(3,6)\n",
    "print(rand_torch,range_torch)\n",
    "\n",
    "#random with image size\n",
    "rand_img_torch = torch.rand(size=(224,224,3))\n",
    "print(rand_img_torch.ndim) \n",
    "\n",
    "#torch zeros\n",
    "zero_torch = torch.zeros(size=(3,4))\n",
    "print(zero_torch)\n",
    "one_torch = torch.ones(size=(4,3))\n",
    "print(one_torch)\n",
    "print(one_torch.T)\n",
    "\n",
    "zero_like_torch = torch.zeros_like(torch.arange(1,10,1))\n",
    "print(zero_like_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.], device='cuda:0')\n",
      "tensor([ 9., 36., 81.], device='cuda:0')\n",
      "tensor([3, 6, 9], device='cuda:0', dtype=torch.int32)\n",
      "tensor([ 9., 36., 81.], device='cuda:0')\n",
      "tensor([ 9., 36., 81.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#파라미터 설정\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],dtype=torch.float32,device=\"cuda\",requires_grad=False)\n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "int_32_tensor = float_16_tensor.type(torch.int32)\n",
    "long_32_tensor = float_16_tensor.type(torch.long)\n",
    "print(float_32_tensor)\n",
    "print(float_32_tensor*float_16_tensor)\n",
    "print(int_32_tensor)\n",
    "print(int_32_tensor * float_32_tensor)\n",
    "print(float_32_tensor * long_32_tensor)\n",
    "#데이터 타입에 유의\n",
    "#Tensors not right datatype => tensor 안 element의 정보를 얻으려면, tensor.dtype에 접근해야함.\n",
    "#Tensors not right shape\n",
    "#Tensors not on right device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals : tensor([1, 4, 9])\n",
      "dot : 14\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3)\n",
    "some_tensor+=10\n",
    "some_tensor*=2\n",
    "print(some_tensor.device)\n",
    "\n",
    "sample_tensor = torch.arange(1,4)\n",
    "#torch 행렬곱(elementwise)\n",
    "print(sample_tensor ,\"*\" ,sample_tensor)\n",
    "print(f\"Equals : {sample_tensor * sample_tensor}\")\n",
    "\n",
    "\n",
    "\n",
    "# torch 행렬곱 (dot) 1x1 + 2x2 + 3x3\n",
    "print(f\"dot : {torch.matmul(sample_tensor,sample_tensor)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0 \n",
    "for i in range(len(sample_tensor)):\n",
    "    value += sample_tensor[i] * sample_tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(torch.matmul(sample_tensor,sample_tensor))\n",
    "\n",
    "#반복문보다 내장 함수가 훨씬 빠르다.\n",
    "#행렬곱은 안쪽의 디멘션이 같아야함.\n",
    "#(3,2)(2,3) / (1,6),(6,1)이어야한다는 이야기.\n",
    "#딥러닝할때 shape에는 에러가 계속 난다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 23,  29,  35],\n",
      "        [ 53,  67,  81],\n",
      "        [ 83, 105, 127]])\n",
      "tensor([[ 23,  29,  35],\n",
      "        [ 53,  67,  81],\n",
      "        [ 83, 105, 127]])\n",
      "tensor([[ 7, 16],\n",
      "        [27, 40],\n",
      "        [55, 72]])\n"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.arange(1,7).reshape(3,-1)\n",
    "tensor_B = torch.arange(7,13).reshape(3,-1) \n",
    "print(torch.matmul(tensor_A ,tensor_B.T))\n",
    "#dot only for 1d dimension\n",
    "print(tensor_A @ tensor_B.T)\n",
    "print(tensor_A * tensor_B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.arange(0,100,step =10,dtype=torch.float32)\n",
    "#dtype이 무조건 float32이여야한다.\n",
    "torch.mean(x)\n",
    "torch.argmax(x)\n",
    "torch.argmin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([ 1,  2,  3,  4, 13,  6,  7,  8,  9])\n",
      "tensor([[ 1,  2,  3,  4, 13,  6,  7,  8,  9],\n",
      "        [ 1,  2,  3,  4, 13,  6,  7,  8,  9],\n",
      "        [ 1,  2,  3,  4, 13,  6,  7,  8,  9],\n",
      "        [ 1,  2,  3,  4, 13,  6,  7,  8,  9],\n",
      "        [ 1,  2,  3,  4, 13,  6,  7,  8,  9]])\n",
      "tensor([ 1,  2,  3,  4, 13,  6,  7,  8,  9,  1,  2,  3,  4, 13,  6,  7,  8,  9,\n",
      "         1,  2,  3,  4, 13,  6,  7,  8,  9,  1,  2,  3,  4, 13,  6,  7,  8,  9,\n",
      "         1,  2,  3,  4, 13,  6,  7,  8,  9])\n"
     ]
    }
   ],
   "source": [
    "#Reshape : 정수 넣은 순서대로 재배열\n",
    "#View 특정 torch를 바라보는 torch 생성.\n",
    "#stacking vstack, hstack\n",
    "#squeeze 1 dimension을 모두 지운다.\n",
    "#unsqueeze 1 dimension을 추가한다.\n",
    "#permute : view를 반환한다.\n",
    "y= torch.arange(1,10)\n",
    "y.reshape(1,9)\n",
    "print(y)\n",
    "z= y.view(1,9)\n",
    "z[0][4]=13\n",
    "print(y)\n",
    "\n",
    "x_vstack = torch.vstack([y,y,y,y,y,])\n",
    "x_hstack = torch.hstack([y,y,y,y,y,])\n",
    "print(x_vstack)\n",
    "print(x_hstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 2, 2])\n",
      "torch.Size([1, 2, 3, 1, 3, 2, 2])\n",
      "torch.Size([1, 2, 3, 1, 1, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#squeeze\n",
    "# 크기가 1인 디멘션을 제거한다.\n",
    "k = torch.arange(0,72).reshape(2,3,1,3,2,-1)\n",
    "print(k.squeeze().shape)\n",
    "\n",
    "#크가기 1인 디멘션을 추가한다.\n",
    "k_unsqueeze = k.unsqueeze(dim=0)\n",
    "print(k_unsqueeze.shape)\n",
    "k_unsqueeze = k_unsqueeze.unsqueeze(dim=3)\n",
    "print(k_unsqueeze.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3]) torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "#permute 순서를 바꿀수 있다.\n",
    "x_original = torch.rand(size=(224,224,3))\n",
    "x_permuted = x_original.permute(2,0,1)  # 인덱스로 차원을 바꾼다. 2->0, 1->2 0->1\n",
    "print(x_original.shape,x_permuted.shape) #contiguous() 써도 됨(메모리)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
